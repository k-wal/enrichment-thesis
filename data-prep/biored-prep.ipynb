{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ac25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "import os\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re\n",
    "import random\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6927989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrepMedMentionDoc():\n",
    "    def __init__(self, filepath):\n",
    "        self.ann_df, self.text = self.load_annotations(filepath)\n",
    "\n",
    "    def change_offset(self, val, title_len):\n",
    "        if val > title_len:\n",
    "            val += 1\n",
    "        return val\n",
    "        \n",
    "    def load_annotations(self, filepath):\n",
    "        file = open(filepath, 'r')\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "        title = lines[0].split('|')[-1].strip()\n",
    "        abstract = lines[1].split('|')[-1].strip()\n",
    "        lines = lines[2:]\n",
    "        \n",
    "        title_len = len(title)\n",
    "        text = title + '. ' + abstract\n",
    "        lines = [line.split('\\t')[1:4] for line in lines]\n",
    "        ann_df = pd.DataFrame(columns=['beg_idx', 'end_idx', 'entity'], data=lines)\n",
    "        ann_df = ann_df[ann_df['beg_idx'].apply(lambda x: str(x).isdigit())]\n",
    "        ann_df['beg_idx'] = pd.to_numeric(ann_df['beg_idx'])\n",
    "        ann_df['end_idx'] = pd.to_numeric(ann_df['end_idx'])\n",
    "        \n",
    "        ann_df['beg_idx'] = ann_df.apply(lambda row: self.change_offset(row['beg_idx'], title_len), axis=1)\n",
    "        ann_df['end_idx'] = ann_df.apply(lambda row: self.change_offset(row['end_idx'], title_len), axis=1)\n",
    "        for index, row in ann_df.iterrows():\n",
    "            if row['entity'] != text[row['beg_idx']:row['end_idx']]:\n",
    "                print('problem')\n",
    "                \n",
    "        return ann_df, text\n",
    "                \n",
    "    def convert_bio(self):\n",
    "        df, text = self.ann_df, self.text\n",
    "        \n",
    "        # BIO tagging entire text\n",
    "        doc = nlp(text)\n",
    "        tokens = []\n",
    "        prev_term_id = ''\n",
    "        tags = []\n",
    "\n",
    "        # go through annotations and mark entities in doc with BIO tags\n",
    "        tags = ['O']*len(doc)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            span = doc.char_span(row['beg_idx'], row['end_idx'], alignment_mode='expand')\n",
    "            for token_idx in range(span.start, span.end):\n",
    "                if token_idx == span.start:\n",
    "                    tags[token_idx] = 'B'\n",
    "                else:\n",
    "                    tags[token_idx] = 'I'\n",
    "\n",
    "        # removing tokens that are whitespaces\n",
    "        tokens = []\n",
    "        old_tags = tags\n",
    "        tags = []\n",
    "        for token, tag in zip(doc, old_tags):\n",
    "            if token.text.strip() != '':\n",
    "                tokens.append(token.text)\n",
    "                tags.append(tag)\n",
    "        text = ' '.join(tokens)\n",
    "\n",
    "        # splitting tags and text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "        df = pd.DataFrame(columns=['sentence', 'word_labels'])\n",
    "        for sent in sentences:\n",
    "            sent_len = len(sent.split())\n",
    "            cur_tags = ','.join(tags[0:sent_len])\n",
    "            # remove current sentence's tags\n",
    "            tags = tags[sent_len:]\n",
    "            df = df.append({'sentence':sent, 'word_labels':cur_tags}, ignore_index=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7149a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrepMedMentionDir():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def prep_to_bio(self, dir_path):\n",
    "        filenames = [f for f in os.listdir(dir_path)]\n",
    "        df = pd.DataFrame(columns=['sentence', 'word_labels'])\n",
    "        for filename in tqdm(filenames):\n",
    "            filepath = dir_path + '/' + filename\n",
    "            try:\n",
    "                prepper = DataPrepMedMentionDoc(filepath)\n",
    "                cur_df = prepper.convert_bio()\n",
    "                df = pd.concat([df, cur_df])\n",
    "            except:\n",
    "                print(filename)\n",
    "        df.to_csv('../corpus/biored/biored_train_full.csv', header=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1bd800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrepBioRedPartial():\n",
    "    def __init__(self, filepath):\n",
    "        self.ann_df, self.text, self.removed = self.load_annotations(filepath)\n",
    "        self.kept = 0\n",
    "\n",
    "\n",
    "    def change_offset(self, val, title_len):\n",
    "        if val > title_len:\n",
    "            val += 1\n",
    "        return val\n",
    "        \n",
    "    def load_annotations(self, filepath):\n",
    "        file = open(filepath, 'r')\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "        title = lines[0].split('|')[-1].strip()\n",
    "        abstract = lines[1].split('|')[-1].strip()\n",
    "        lines = lines[2:]\n",
    "        \n",
    "        title_len = len(title)\n",
    "        text = title + '. ' + abstract\n",
    "        \n",
    "        removed = 0\n",
    "        partial_lines = []\n",
    "        for line in lines: \n",
    "            line = line.split('\\t')\n",
    "            # remove 60% of all annotations\n",
    "            if random.random() > 0.4:\n",
    "                removed += 1\n",
    "                continue\n",
    "            partial_lines.append(line[1:4])\n",
    "        lines = partial_lines\n",
    "        \n",
    "        ann_df = pd.DataFrame(columns=['beg_idx', 'end_idx', 'entity'], data=lines)\n",
    "        ann_df = ann_df[ann_df['beg_idx'].apply(lambda x: str(x).isdigit())]\n",
    "        ann_df['beg_idx'] = pd.to_numeric(ann_df['beg_idx'])\n",
    "        ann_df['end_idx'] = pd.to_numeric(ann_df['end_idx'])\n",
    "        \n",
    "        ann_df['beg_idx'] = ann_df.apply(lambda row: self.change_offset(row['beg_idx'], title_len), axis=1)\n",
    "        ann_df['end_idx'] = ann_df.apply(lambda row: self.change_offset(row['end_idx'], title_len), axis=1)\n",
    "        for index, row in ann_df.iterrows():\n",
    "            if row['entity'] != text[row['beg_idx']:row['end_idx']]:\n",
    "                print('problem')\n",
    "                \n",
    "        return ann_df, text, removed\n",
    "                \n",
    "    def convert_bio(self):\n",
    "        df, text = self.ann_df, self.text\n",
    "        \n",
    "        # BIO tagging entire text\n",
    "        doc = nlp(text)\n",
    "        tokens = []\n",
    "        prev_term_id = ''\n",
    "        tags = []\n",
    "\n",
    "        # go through annotations and mark entities in doc with BIO tags\n",
    "        tags = ['O']*len(doc)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            span = doc.char_span(row['beg_idx'], row['end_idx'], alignment_mode='expand')\n",
    "            for token_idx in range(span.start, span.end):\n",
    "                if token_idx == span.start:\n",
    "                    tags[token_idx] = 'B'\n",
    "                    self.kept += 1\n",
    "                else:\n",
    "                    tags[token_idx] = 'I'\n",
    "\n",
    "        # removing tokens that are whitespaces\n",
    "        tokens = []\n",
    "        old_tags = tags\n",
    "        tags = []\n",
    "        for token, tag in zip(doc, old_tags):\n",
    "            if token.text.strip() != '':\n",
    "                tokens.append(token.text)\n",
    "                tags.append(tag)\n",
    "        text = ' '.join(tokens)\n",
    "\n",
    "        # splitting tags and text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "        df = pd.DataFrame(columns=['sentence', 'word_labels'])\n",
    "        for sent in sentences:\n",
    "            sent_len = len(sent.split())\n",
    "            cur_tags = ','.join(tags[0:sent_len])\n",
    "            # remove current sentence's tags\n",
    "            tags = tags[sent_len:]\n",
    "            df = df.append({'sentence':sent, 'word_labels':cur_tags}, ignore_index=True)\n",
    "        return df, self.removed, self.kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50623c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrepBioRedDirPartial():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def prep_to_bio(self, dir_path):\n",
    "        removed = 0\n",
    "        kept = 0\n",
    "        filenames = [f for f in os.listdir(dir_path)]\n",
    "        df = pd.DataFrame(columns=['sentence', 'word_labels'])\n",
    "        for filename in tqdm(filenames):\n",
    "            filepath = dir_path + '/' + filename\n",
    "            try:\n",
    "                prepper = DataPrepBioRedPartial(filepath)\n",
    "                cur_df, cur_removed, cur_kept = prepper.convert_bio()\n",
    "                df = pd.concat([df, cur_df])\n",
    "                removed += cur_removed\n",
    "                kept += cur_kept\n",
    "            except:\n",
    "                print(filename)\n",
    "        #df.to_csv('../corpus/biored/biored_train_partial_all_40.csv', header=True)\n",
    "        print(\"removed entities: \", removed)\n",
    "        print(\"kept entities: \", kept)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac76246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../corpus/biored/test_docs/19531695.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b80514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████▍                                                                                                           | 52/501 [00:02<00:20, 21.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████████████▋                                                                                     | 142/501 [00:06<00:14, 24.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8944024.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 501/501 [00:21<00:00, 23.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed entities:  13322\n",
      "kept entities:  6783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catechol - O - methyltransferase ( COMT ) gene...</td>\n",
       "      <td>O,O,O,O,O,O,B,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A common single nucleotide polymorphism ( SNP ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We sequenced exon IV of COMT gene in search fo...</td>\n",
       "      <td>O,O,O,O,O,B,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genotype frequencies of the G472A SNP varied s...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Using a genotype test , we found a trend to po...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS : A case - control study was carried o...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genomic DNA was extracted from blood samples ,...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data were adjusted for sex , age , migraine hi...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RESULTS : There was no association between ind...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CONCLUSION : These findings do not support a f...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5145 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  \\\n",
       "0   Catechol - O - methyltransferase ( COMT ) gene...   \n",
       "1   A common single nucleotide polymorphism ( SNP ...   \n",
       "2   We sequenced exon IV of COMT gene in search fo...   \n",
       "3   Genotype frequencies of the G472A SNP varied s...   \n",
       "4   Using a genotype test , we found a trend to po...   \n",
       "..                                                ...   \n",
       "2   METHODS : A case - control study was carried o...   \n",
       "3   Genomic DNA was extracted from blood samples ,...   \n",
       "4   Data were adjusted for sex , age , migraine hi...   \n",
       "5   RESULTS : There was no association between ind...   \n",
       "6   CONCLUSION : These findings do not support a f...   \n",
       "\n",
       "                                          word_labels  \n",
       "0   O,O,O,O,O,O,B,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "2   O,O,O,O,O,B,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "3   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "4   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "..                                                ...  \n",
       "2     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "3           O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "4         O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "5           O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "6   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "\n",
       "[5145 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = '../corpus/biored/train_docs'\n",
    "prepper = DataPrepBioRedDirPartial()\n",
    "prepper.prep_to_bio(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1c43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ea2ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████▍                                                                                                           | 52/501 [00:02<00:21, 21.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 501/501 [00:22<00:00, 21.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catechol - O - methyltransferase ( COMT ) gene...</td>\n",
       "      <td>B,I,I,I,I,O,B,O,O,O,O,O,O,O,O,B,O,O,B,I,O,O,B,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A common single nucleotide polymorphism ( SNP ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,B,O,O,O,O,B,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We sequenced exon IV of COMT gene in search fo...</td>\n",
       "      <td>O,O,O,O,O,B,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genotype frequencies of the G472A SNP varied s...</td>\n",
       "      <td>O,O,O,O,B,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Using a genotype test , we found a trend to po...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS : A case - control study was carried o...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genomic DNA was extracted from blood samples ,...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data were adjusted for sex , age , migraine hi...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,B,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RESULTS : There was no association between ind...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,B,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CONCLUSION : These findings do not support a f...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,B,B,I,I,I,I,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  \\\n",
       "0   Catechol - O - methyltransferase ( COMT ) gene...   \n",
       "1   A common single nucleotide polymorphism ( SNP ...   \n",
       "2   We sequenced exon IV of COMT gene in search fo...   \n",
       "3   Genotype frequencies of the G472A SNP varied s...   \n",
       "4   Using a genotype test , we found a trend to po...   \n",
       "..                                                ...   \n",
       "2   METHODS : A case - control study was carried o...   \n",
       "3   Genomic DNA was extracted from blood samples ,...   \n",
       "4   Data were adjusted for sex , age , migraine hi...   \n",
       "5   RESULTS : There was no association between ind...   \n",
       "6   CONCLUSION : These findings do not support a f...   \n",
       "\n",
       "                                          word_labels  \n",
       "0   B,I,I,I,I,O,B,O,O,O,O,O,O,O,O,B,O,O,B,I,O,O,B,...  \n",
       "1   O,O,O,O,O,O,O,O,O,B,O,O,O,O,B,O,O,O,O,O,O,O,O,...  \n",
       "2   O,O,O,O,O,B,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "3   O,O,O,O,B,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "4   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,O,...  \n",
       "..                                                ...  \n",
       "2     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,O,O,O,O  \n",
       "3           O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "4         O,O,O,O,O,O,O,O,B,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "5           O,O,O,O,O,O,O,O,O,O,B,O,O,O,O,O,O,O,O,O,O  \n",
       "6   O,O,O,O,O,O,O,O,O,O,O,B,B,I,I,I,I,O,O,O,O,O,O,...  \n",
       "\n",
       "[5153 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = '../corpus/biored/train_docs'\n",
    "prepper = DataPrepMedMentionDir()\n",
    "prepper.prep_to_bio(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4823e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delirium B\n",
      "in O\n",
      "a O\n",
      "patient B\n",
      "with O\n",
      "toxic O\n",
      "flecainide B\n",
      "plasma O\n",
      "concentrations O\n",
      ": O\n",
      "the O\n",
      "role O\n",
      "of O\n",
      "a O\n",
      "pharmacokinetic O\n",
      "drug O\n",
      "interaction O\n",
      "with O\n",
      "paroxetine B\n",
      ".. O\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for a,b in zip(df.iloc[index]['sentence'].split(' '), df.iloc[index]['word_labels'].split(',')):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed196430",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../corpus/biored/Dev.Pubtator','r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "docs = text.split('\\n\\n')\n",
    "for doc in docs: \n",
    "    filename = doc.split('|')[0]\n",
    "    file = open('../corpus/biored/dev_docs/' + filename + '.txt', 'w')\n",
    "    file.write(doc)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d02911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e73740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254aef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
