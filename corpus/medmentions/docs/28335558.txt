28335558|t|Modeling the Development of Audiovisual Cue Integration in Speech Perception
28335558|a|Adult speech perception is generally enhanced when information is provided from multiple modalities. In contrast, infants do not appear to benefit from combining auditory and visual speech information early in development. This is true despite the fact that both modalities are important to speech comprehension even at early stages of language acquisition. How then do listeners learn how to process auditory and visual information as part of a unified signal? In the auditory domain, statistical learning processes provide an excellent mechanism for acquiring phonological categories. Is this also true for the more complex problem of acquiring audiovisual correspondences, which require the learner to integrate information from multiple modalities? In this paper, we present simulations using Gaussian mixture models (GMMs) that learn cue weights and combine cues on the basis of their distributional statistics. First, we simulate the developmental process of acquiring phonological categories from auditory and visual cues, asking whether simple statistical learning approaches are sufficient for learning multi-modal representations. Second, we use this time course information to explain audiovisual speech perception in adult perceivers, including cases where auditory and visual input are mismatched. Overall, we find that domain-general statistical learning techniques allow us to model the developmental trajectory of audiovisual cue integration in speech, and in turn, allow us to better understand the mechanisms that give rise to unified percepts based on multiple cues.
28335558	0	8	Modeling	T062	C0870071
28335558	13	24	Development	T169	C1527148
28335558	28	39	Audiovisual	T080	C0205556
28335558	40	43	Cue	T078	C0010439
28335558	44	55	Integration	T040	C0679019
28335558	59	76	Speech Perception	T041	C0037826
28335558	77	82	Adult	T100	C0001675
28335558	83	100	speech perception	T041	C0037826
28335558	128	139	information	T078	C1533716
28335558	157	165	multiple	T081	C0439064
28335558	166	176	modalities	T078	C0695347
28335558	191	198	infants	T100	C0021270
28335558	216	223	benefit	T081	C0814225
28335558	239	247	auditory	T169	C0439825
28335558	252	258	visual	T169	C0234621
28335558	259	265	speech	T040	C0037817
28335558	266	277	information	T078	C1533716
28335558	278	298	early in development	T067	C0870455
28335558	340	350	modalities	T078	C0695347
28335558	368	374	speech	T040	C0037817
28335558	375	388	comprehension	T041	C0162340
28335558	397	409	early stages	T079	C2363430
28335558	413	433	language acquisition	T041	C0023013
28335558	447	456	listeners	T098	C1257890
28335558	457	462	learn	T041	C0023185
28335558	470	477	process	T067	C1522240
28335558	478	486	auditory	T169	C0439825
28335558	491	497	visual	T169	C0234621
28335558	498	509	information	T078	C1533716
28335558	523	530	unified	T080	C1706076
28335558	546	554	auditory	T169	C0439825
28335558	563	574	statistical	T090	C0038215
28335558	575	583	learning	T041	C0023185
28335558	584	593	processes	T067	C1522240
28335558	605	614	excellent	T080	C1961136
28335558	615	624	mechanism	T169	C0441712
28335558	639	651	phonological	T090	C0597725
28335558	652	662	categories	T170	C0683312
28335558	695	702	complex	T080	C0439855
28335558	703	710	problem	T033	C0033213
28335558	724	735	audiovisual	T080	C0205556
28335558	771	778	learner	T098	C1257890
28335558	782	791	integrate	T040	C0679019
28335558	792	803	information	T078	C1533716
28335558	809	817	multiple	T081	C0439064
28335558	818	828	modalities	T078	C0695347
28335558	856	867	simulations	T062	C0679083
28335558	874	897	Gaussian mixture models	T170	C3161035
28335558	899	903	GMMs	T170	C3161035
28335558	916	919	cue	T078	C0010439
28335558	920	927	weights	T081	C0043100
28335558	940	944	cues	T078	C0010439
28335558	982	992	statistics	T090	C0038215
28335558	1004	1012	simulate	T062	C0679083
28335558	1017	1030	developmental	T080	C0458003
28335558	1031	1038	process	T067	C1522240
28335558	1052	1064	phonological	T090	C0597725
28335558	1065	1075	categories	T170	C0683312
28335558	1081	1089	auditory	T169	C0439825
28335558	1094	1100	visual	T169	C0234621
28335558	1101	1105	cues	T078	C0010439
28335558	1129	1140	statistical	T090	C0038215
28335558	1141	1149	learning	T041	C0023185
28335558	1180	1188	learning	T041	C0023185
28335558	1189	1200	multi-modal	T080	C0205556
28335558	1250	1261	information	T078	C1533716
28335558	1273	1284	audiovisual	T080	C0205556
28335558	1285	1302	speech perception	T041	C0037826
28335558	1306	1311	adult	T100	C0001675
28335558	1312	1322	perceivers	T098	C1257890
28335558	1346	1354	auditory	T169	C0439825
28335558	1359	1365	visual	T169	C0234621
28335558	1376	1386	mismatched	T080	C1881865
28335558	1425	1436	statistical	T090	C0038215
28335558	1437	1445	learning	T041	C0023185
28335558	1446	1456	techniques	T169	C0449851
28335558	1469	1474	model	T170	C3161035
28335558	1479	1503	developmental trajectory	T170	C0282574
28335558	1507	1518	audiovisual	T080	C0205556
28335558	1519	1522	cue	T078	C0010439
28335558	1523	1534	integration	T040	C0679019
28335558	1538	1544	speech	T040	C0037817
28335558	1593	1603	mechanisms	T169	C0441712
28335558	1622	1629	unified	T080	C1706076
28335558	1630	1638	percepts	T041	C0030971
28335558	1648	1656	multiple	T081	C0439064
28335558	1657	1661	cues	T078	C0010439