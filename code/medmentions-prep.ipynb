{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ac25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "import os\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6927989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrepMedMentionDoc():\n",
    "    def __init__(self, filepath):\n",
    "        self.ann_df, self.text = self.load_annotations(filepath)\n",
    "        self.kept = 0\n",
    "\n",
    "    def change_offset(self, val, title_len):\n",
    "        if val > title_len:\n",
    "            val += 1\n",
    "        return val\n",
    "        \n",
    "    def load_annotations(self, filepath):\n",
    "        file = open(filepath, 'r')\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "        title = lines[0].split('|')[-1].strip()\n",
    "        abstract = lines[1].split('|')[-1].strip()\n",
    "        lines = lines[2:]\n",
    "        \n",
    "        title_len = len(title)\n",
    "        text = title + '. ' + abstract\n",
    "        lines = [line.split('\\t')[1:4] for line in lines]\n",
    "        ann_df = pd.DataFrame(columns=['beg_idx', 'end_idx', 'entity'], data=lines)\n",
    "        ann_df['beg_idx'] = pd.to_numeric(ann_df['beg_idx'])\n",
    "        ann_df['end_idx'] = pd.to_numeric(ann_df['end_idx'])\n",
    "        \n",
    "        ann_df['beg_idx'] = ann_df.apply(lambda row: self.change_offset(row['beg_idx'], title_len), axis=1)\n",
    "        ann_df['end_idx'] = ann_df.apply(lambda row: self.change_offset(row['end_idx'], title_len), axis=1)\n",
    "        for index, row in ann_df.iterrows():\n",
    "            if row['entity'] != text[row['beg_idx']:row['end_idx']]:\n",
    "                print('problem')\n",
    "                \n",
    "        return ann_df, text\n",
    "                \n",
    "    def convert_bio(self):\n",
    "        df, text = self.ann_df, self.text\n",
    "        \n",
    "        # BIO tagging entire text\n",
    "        doc = nlp(text)\n",
    "        tokens = []\n",
    "        prev_term_id = ''\n",
    "        tags = []\n",
    "\n",
    "        # go through annotations and mark entities in doc with BIO tags\n",
    "        tags = ['O']*len(doc)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            self.kept += 1\n",
    "            span = doc.char_span(row['beg_idx'], row['end_idx'], alignment_mode='expand')\n",
    "            for token_idx in range(span.start, span.end):\n",
    "                if token_idx == span.start:\n",
    "                    tags[token_idx] = 'B'\n",
    "                else:\n",
    "                    tags[token_idx] = 'I'\n",
    "\n",
    "        # removing tokens that are whitespaces\n",
    "        tokens = []\n",
    "        old_tags = tags\n",
    "        tags = []\n",
    "        for token, tag in zip(doc, old_tags):\n",
    "            if token.text.strip() != '':\n",
    "                tokens.append(token.text)\n",
    "                tags.append(tag)\n",
    "        text = ' '.join(tokens)\n",
    "\n",
    "        # splitting tags and text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "        df = pd.DataFrame(columns=['sentence', 'word_labels'])\n",
    "        for sent in sentences:\n",
    "            sent_len = len(sent.split())\n",
    "            cur_tags = ','.join(tags[0:sent_len])\n",
    "            # remove current sentence's tags\n",
    "            tags = tags[sent_len:]\n",
    "            df = df.append({'sentence':sent, 'word_labels':cur_tags}, ignore_index=True)\n",
    "        return df, self.kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7149a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrepMedMentionDir():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def prep_to_bio(self, dir_path):\n",
    "        kept = 0\n",
    "        filenames = [f for f in os.listdir(dir_path)]\n",
    "        df = pd.DataFrame(columns=['sentence', 'word_labels'])\n",
    "        for filename in tqdm(filenames):\n",
    "            filepath = dir_path + '/' + filename\n",
    "            try:\n",
    "                prepper = DataPrepMedMentionDoc(filepath)\n",
    "                cur_df, cur_kept = prepper.convert_bio()\n",
    "                df = pd.concat([df, cur_df])\n",
    "                kept += cur_kept\n",
    "            except:\n",
    "                print(filename)\n",
    "        df.to_csv('../corpus/medmentions/medmentions_small_bio.csv', header=True)\n",
    "        print(\"total annotations: \", kept)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac76246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../corpus/medmentions/docs/27358636.txt'\n",
    "dir_path = '../corpus/medmentions/docs_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b80514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepper = DataPrepMedMentionDoc(filepath)\n",
    "df = prepper.convert_bio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ea2ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████▉                                                                                                             | 332/4393 [00:14<03:02, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████████████▌                                                                              | 1447/4393 [01:03<02:20, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "27460729.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 3749/4393 [02:44<00:26, 24.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "27059693.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 3934/4393 [02:52<00:20, 22.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "27801889.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4393/4393 [03:12<00:00, 22.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total annotations:  203124\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haemophilus influenzae type b meningitis in a ...</td>\n",
       "      <td>B,I,I,I,I,O,O,B,O,B,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Invasive Haemophilus influenzae type b ( Hib )...</td>\n",
       "      <td>B,I,I,I,I,I,I,I,I,O,O,O,O,O,O,B,I,O,O,B,I,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We report a case of a fifteen - months - old g...</td>\n",
       "      <td>O,B,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,O,B,O,O,B,I,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She was irritable and the Brudzinski 's sign w...</td>\n",
       "      <td>O,O,B,O,O,B,I,I,O,B,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The cerebrospinal fluid ( CSF ) analysis showe...</td>\n",
       "      <td>O,B,I,O,B,O,O,O,B,O,B,I,I,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hPDSCs exerted inhibitory actions on inflammat...</td>\n",
       "      <td>B,O,O,O,O,O,B,O,O,O,O,O,O,B,B,O,O,O,O,O,B,I,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The preservation of cells expressing lysozyme ...</td>\n",
       "      <td>O,B,O,B,O,B,O,O,B,O,O,O,O,O,B,B,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Both preventive and therapeutic efficacies of ...</td>\n",
       "      <td>O,O,O,B,O,O,B,O,O,O,B,I,I,I,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Label - free quantification was used to identi...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,B,O,O,B,I,O,B,B,O,O,O,B,I,I,I,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hPDSCs may be a useful prophylactic and therap...</td>\n",
       "      <td>B,O,O,O,O,B,O,B,B,I,O,B,I,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  \\\n",
       "0   Haemophilus influenzae type b meningitis in a ...   \n",
       "1   Invasive Haemophilus influenzae type b ( Hib )...   \n",
       "2   We report a case of a fifteen - months - old g...   \n",
       "3   She was irritable and the Brudzinski 's sign w...   \n",
       "4   The cerebrospinal fluid ( CSF ) analysis showe...   \n",
       "..                                                ...   \n",
       "7   hPDSCs exerted inhibitory actions on inflammat...   \n",
       "8   The preservation of cells expressing lysozyme ...   \n",
       "9   Both preventive and therapeutic efficacies of ...   \n",
       "10  Label - free quantification was used to identi...   \n",
       "11  hPDSCs may be a useful prophylactic and therap...   \n",
       "\n",
       "                                          word_labels  \n",
       "0                             B,I,I,I,I,O,O,B,O,B,O,O  \n",
       "1         B,I,I,I,I,I,I,I,I,O,O,O,O,O,O,B,I,O,O,B,I,O  \n",
       "2   O,B,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,O,B,O,O,B,I,...  \n",
       "3                               O,O,B,O,O,B,I,I,O,B,O  \n",
       "4                         O,B,I,O,B,O,O,O,B,O,B,I,I,O  \n",
       "..                                                ...  \n",
       "7   B,O,O,O,O,O,B,O,O,O,O,O,O,B,B,O,O,O,O,O,B,I,O,...  \n",
       "8                 O,B,O,B,O,B,O,O,B,O,O,O,O,O,B,B,O,O  \n",
       "9                       O,O,O,B,O,O,B,O,O,O,B,I,I,I,O  \n",
       "10  O,O,O,O,O,O,O,O,B,O,O,B,I,O,B,B,O,O,O,B,I,I,I,...  \n",
       "11                        B,O,O,O,O,B,O,B,B,I,O,B,I,O  \n",
       "\n",
       "[47161 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepper = DataPrepMedMentionDir()\n",
    "prepper.prep_to_bio(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4823e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWI B\n",
      "and O\n",
      "quantitative B\n",
      "measurement I\n",
      "of O\n",
      "ADC B\n",
      "values B\n",
      "can O\n",
      "be O\n",
      "used O\n",
      "in O\n",
      "differential B\n",
      "diagnosis I\n",
      "of O\n",
      "benign B\n",
      "and O\n",
      "malignant B\n",
      "liver B\n",
      "lesions I\n",
      "and O\n",
      "also O\n",
      "in O\n",
      "the O\n",
      "diagnosis B\n",
      "and O\n",
      "differentiation B\n",
      "of O\n",
      "hemangiomas B\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "index = 15\n",
    "for a,b in zip(df.iloc[index]['sentence'].split(' '), df.iloc[index]['word_labels'].split(',')):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed196430",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../corpus/medmentions/corpus_pubtator_small.txt','r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "docs = text.split('\\n\\n')\n",
    "for doc in docs: \n",
    "    filename = doc.split('|')[0]\n",
    "    file = open('../corpus/medmentions/docs_small/' + filename + '.txt', 'w')\n",
    "    file.write(doc)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d02911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e73740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254aef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
