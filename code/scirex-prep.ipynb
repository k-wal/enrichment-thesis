{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b375f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c279f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e01f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SciRexDataPrepDoc():\n",
    "    def __init__(self):\n",
    "        self.v = 0\n",
    "    \n",
    "    def convert_to_df(self, words, sentences, anns):\n",
    "        df = []\n",
    "        kept = 0\n",
    "        \n",
    "        annotations = ['O']*len(words)\n",
    "        for ann in anns:\n",
    "            beg, end = int(ann[0]), int(ann[1])\n",
    "            kept += 1\n",
    "            annotations[beg] = 'B'\n",
    "            \n",
    "            for i in range(beg+1, end):\n",
    "                annotations[i] = 'I'\n",
    "        \n",
    "        for sent in sentences:\n",
    "            beg, end = sent[0], sent[1]\n",
    "            cur_sent = {}\n",
    "            cur_sent['word_labels'] = ','.join(annotations[beg:end])\n",
    "            cur_sent['sentence'] = ' '.join(words[beg:end])\n",
    "            df.append(cur_sent)\n",
    "            \n",
    "        df = pd.DataFrame(df)\n",
    "        return df, kept            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c146e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SciRexDataPrepDir():\n",
    "    def __init__(self):\n",
    "        self.v = 0\n",
    "\n",
    "    def get_df(self, inpath, outpath = ''):\n",
    "        df = pd.DataFrame(columns=['sentence', 'word_labels'])\n",
    "        doc_prepper = SciRexDataPrepDoc()\n",
    "        with open(inpath, 'r') as json_file:\n",
    "            json_list = list(json_file)\n",
    "\n",
    "        kept = 0\n",
    "        #print(len(json_list))\n",
    "        for json_str in tqdm(json_list):\n",
    "            result = json.loads(json_str)\n",
    "            words = result['words']\n",
    "            anns = result['ner']\n",
    "            sentences = result['sentences']\n",
    "            cur_df, cur_kept = doc_prepper.convert_to_df(words, sentences, anns)\n",
    "            kept += cur_kept\n",
    "            df = pd.concat([df, cur_df], ignore_index = True)\n",
    "        df.to_csv(outpath, header=True)\n",
    "        print(\"total annotations: \", kept)\n",
    "        return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb62c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 673.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total annotations:  23365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = '../corpus/scirex/dev.jsonl'\n",
    "outpath = '../corpus/scirex/scirex_train_bio.csv'\n",
    "prepper = SciRexDataPrepDir()\n",
    "df = prepper.get_df(filepath, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6dd1cff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>document : Attention Boosted Sequential Infere...</td>\n",
       "      <td>O,O,B,I,I,I,I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attention mechanism has been proven effective ...</td>\n",
       "      <td>B,I,O,O,O,O,O,B,I,I,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper proposes an attention boosted natur...</td>\n",
       "      <td>O,O,O,O,B,I,I,I,I,I,O,B,O,O,B,I,O,B,I,I,I,I,I,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This makes the inference model aESIM has the a...</td>\n",
       "      <td>O,O,O,B,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,B,I,I,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The empirical studies on the SNLI , MultiNLI a...</td>\n",
       "      <td>O,O,O,O,O,B,O,B,O,B,O,O,O,B,O,O,O,O,O,B,I,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17866</th>\n",
       "      <td>We have presented a scene text detector that d...</td>\n",
       "      <td>O,O,O,O,B,I,I,O,O,O,B,I,I,I,I,O,O,O,O,O,O,B,I,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867</th>\n",
       "      <td>By incorporating proper loss functions , the d...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17868</th>\n",
       "      <td>The experiments on standard benchmarks confirm...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,O,B,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17869</th>\n",
       "      <td>Possible directions for future research includ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,B,I,O,O,B,I,I,I,I,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17870</th>\n",
       "      <td>bibliography : References</td>\n",
       "      <td>O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17871 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0      document : Attention Boosted Sequential Infere...   \n",
       "1      Attention mechanism has been proven effective ...   \n",
       "2      This paper proposes an attention boosted natur...   \n",
       "3      This makes the inference model aESIM has the a...   \n",
       "4      The empirical studies on the SNLI , MultiNLI a...   \n",
       "...                                                  ...   \n",
       "17866  We have presented a scene text detector that d...   \n",
       "17867  By incorporating proper loss functions , the d...   \n",
       "17868  The experiments on standard benchmarks confirm...   \n",
       "17869  Possible directions for future research includ...   \n",
       "17870                          bibliography : References   \n",
       "\n",
       "                                             word_labels  \n",
       "0                                          O,O,B,I,I,I,I  \n",
       "1                                  B,I,O,O,O,O,O,B,I,I,O  \n",
       "2      O,O,O,O,B,I,I,I,I,I,O,B,O,O,B,I,O,B,I,I,I,I,I,...  \n",
       "3      O,O,O,B,I,I,O,O,O,O,O,O,O,O,O,O,O,O,O,B,I,I,O,...  \n",
       "4            O,O,O,O,O,B,O,B,O,B,O,O,O,B,O,O,O,O,O,B,I,O  \n",
       "...                                                  ...  \n",
       "17866    O,O,O,O,B,I,I,O,O,O,B,I,I,I,I,O,O,O,O,O,O,B,I,O  \n",
       "17867    O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "17868        O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B,O,B,O  \n",
       "17869  O,O,O,O,O,O,O,O,O,O,O,O,B,I,O,O,B,I,I,I,I,O,O,...  \n",
       "17870                                              O,O,O  \n",
       "\n",
       "[17871 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c4b479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671fbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
