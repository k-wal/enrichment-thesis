{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68908146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "import os\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a961ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "infix_re = re.compile('[\\(.,\\)?]')\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    return Tokenizer(nlp.vocab, infix_finditer=infix_re.finditer)\n",
    "nlp.tokenizer = custom_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f11561",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrepBIO():\n",
    "    \"\"\"Load annotations and convert them to BIO Tags\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # load annotations file and convert to BIO tags\n",
    "    # return DataFrame with the columns: [file, sentence, BIO tags]\n",
    "    # filename: filename without any extensions\n",
    "    # dir_path: path of directory containing all files \n",
    "    def load_annotations_file_bio(self, filename, dir_path):\n",
    "        txt_path = dir_path + filename + '.txt'\n",
    "        ann_path = dir_path + filename + '.ann'\n",
    "\n",
    "        # load text\n",
    "        file = open(txt_path, 'r')\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "\n",
    "        df = pd.read_csv(ann_path, sep='\\t', names=['term_id', 'source', 'beg_idx', 'end_idx', 'entity'], header=None)\n",
    "        # drop annotations that are not terms\n",
    "        df = df[df['term_id'].str.contains('T')]\n",
    "        # drop beg_idx, end_idx columns\n",
    "        df['entity'] = df['beg_idx']\n",
    "        df = df.drop(columns=['beg_idx', 'end_idx'])\n",
    "        # separating source and spans\n",
    "        df[['source', 'beg_idx', 'end_idx']] = df['source'].str.split(' ', 2, expand=True)\n",
    "        df = df[df['source'] != 'Number']\n",
    "        df = df[df['source'] != 'Condition-Unit']\n",
    "        df['beg_idx'] = pd.to_numeric(df['beg_idx'])\n",
    "        df['end_idx'] = pd.to_numeric(df['end_idx'])\n",
    "\n",
    "        # BIO tagging entire text\n",
    "        doc = nlp(text)\n",
    "        tokens = []\n",
    "        prev_term_id = ''\n",
    "        tags = []\n",
    "\n",
    "        # go through annotations and mark entities in doc with BIO tags\n",
    "        tags = ['O']*len(doc)\n",
    "\n",
    "        kept = 0\n",
    "        for index, row in df.iterrows():\n",
    "            kept += 1\n",
    "            span = doc.char_span(row['beg_idx'], row['end_idx'], alignment_mode='expand')\n",
    "            for token_idx in range(span.start, span.end):\n",
    "                if token_idx == span.start:\n",
    "                    tags[token_idx] = 'B'\n",
    "                else:\n",
    "                    tags[token_idx] = 'I'\n",
    "\n",
    "        # removing tokens that are whitespaces\n",
    "        tokens = []\n",
    "        old_tags = tags\n",
    "        tags = []\n",
    "        for token, tag in zip(doc, old_tags):\n",
    "            if token.text.strip() != '':\n",
    "                tokens.append(token.text)\n",
    "                tags.append(tag)\n",
    "        text = ' '.join(tokens)\n",
    "\n",
    "        # splitting tags and text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "        df = pd.DataFrame(columns=['file', 'sentence', 'word_labels'])\n",
    "        for sent in sentences:\n",
    "            sent_len = len(sent.split())\n",
    "            cur_tags = ','.join(tags[0:sent_len])\n",
    "            # remove current sentence's tags\n",
    "            tags = tags[sent_len:]\n",
    "            df = df.append({'file': filename, 'sentence':sent, 'word_labels':cur_tags}, ignore_index=True)\n",
    "        return df, kept\n",
    "    \n",
    "    # load annotations of all files in directory and convert to BIO tags\n",
    "    # return DataFrame with the columns: [file, sentence, BIO tags]\n",
    "    # dir_path: path of directory containing all files \n",
    "    def load_annotations_dir_bio(self, dir_path):\n",
    "        filenames = [f.split('.')[0] for f in os.listdir(dir_path) if f.split('.')[1] == 'txt']\n",
    "        df = pd.DataFrame(columns=['file', 'sentence', 'word_labels'])\n",
    "        kept = 0\n",
    "        for filename in tqdm(filenames):\n",
    "            #print(filename)\n",
    "            try:\n",
    "                cur_df, cur_kept = self.load_annotations_file_bio(filename, dir_path)\n",
    "                kept += cur_kept\n",
    "            except:\n",
    "                print(filename)\n",
    "            df = pd.concat([df, cur_df])\n",
    "        print(\"total annotations: \", kept)\n",
    "        df.to_csv('../corpus/matpro/matpro_bio_tags.csv', header=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f47b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../corpus/matpro/data/'\n",
    "prepper = DataPrepBIO()\n",
    "filename = '101002adma200903953'\n",
    "df = prepper.load_annotations_file_bio(filename, dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50174b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 230/230 [00:10<00:00, 21.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total annotations:  15625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = '../corpus/matpro/data/'\n",
    "prepper = DataPrepBIO()\n",
    "df = prepper.load_annotations_dir_bio(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "199cceb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101016jjallcom201511182</td>\n",
       "      <td>10 .</td>\n",
       "      <td>O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101016jjallcom201511182</td>\n",
       "      <td>1016/j .</td>\n",
       "      <td>O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101016jjallcom201511182</td>\n",
       "      <td>jallcom .</td>\n",
       "      <td>O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101016jjallcom201511182</td>\n",
       "      <td>2015 .</td>\n",
       "      <td>O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101016jjallcom201511182</td>\n",
       "      <td>11 .</td>\n",
       "      <td>O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101016jjpowsour201601014</td>\n",
       "      <td>After the adsorption , the resin was filtered ...</td>\n",
       "      <td>O,O,O,O,O,B,O,B,O,B,O,O,O,B,B,O,O,B,O,B,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101016jjpowsour201601014</td>\n",
       "      <td>The resulting product was carbonized at 750 de...</td>\n",
       "      <td>O,O,B,O,B,O,O,O,O,O,O,O,O,B,O,O,O,B,I,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101016jjpowsour201601014</td>\n",
       "      <td>Finally , the black-colored product was furthe...</td>\n",
       "      <td>O,O,O,B,B,O,O,B,O,O,B,O,B,I,O,B,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101016jjpowsour201601014</td>\n",
       "      <td>For comparison , pure carbon was prepared usin...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101016jjpowsour201601014</td>\n",
       "      <td>Mo2C was bought from Hunan Guangyuan Company a...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4558 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file  \\\n",
       "0    101016jjallcom201511182   \n",
       "1    101016jjallcom201511182   \n",
       "2    101016jjallcom201511182   \n",
       "3    101016jjallcom201511182   \n",
       "4    101016jjallcom201511182   \n",
       "..                       ...   \n",
       "8   101016jjpowsour201601014   \n",
       "9   101016jjpowsour201601014   \n",
       "10  101016jjpowsour201601014   \n",
       "11  101016jjpowsour201601014   \n",
       "12  101016jjpowsour201601014   \n",
       "\n",
       "                                             sentence  \\\n",
       "0                                                10 .   \n",
       "1                                            1016/j .   \n",
       "2                                           jallcom .   \n",
       "3                                              2015 .   \n",
       "4                                                11 .   \n",
       "..                                                ...   \n",
       "8   After the adsorption , the resin was filtered ...   \n",
       "9   The resulting product was carbonized at 750 de...   \n",
       "10  Finally , the black-colored product was furthe...   \n",
       "11  For comparison , pure carbon was prepared usin...   \n",
       "12  Mo2C was bought from Hunan Guangyuan Company a...   \n",
       "\n",
       "                                          word_labels  \n",
       "0                                                 O,O  \n",
       "1                                                 O,O  \n",
       "2                                                 O,O  \n",
       "3                                                 O,O  \n",
       "4                                                 O,O  \n",
       "..                                                ...  \n",
       "8   O,O,O,O,O,B,O,B,O,B,O,O,O,B,B,O,O,B,O,B,O,O,O,...  \n",
       "9     O,O,B,O,B,O,O,O,O,O,O,O,O,B,O,O,O,B,I,O,O,O,O,O  \n",
       "10            O,O,O,B,B,O,O,B,O,O,B,O,B,I,O,B,O,O,O,O  \n",
       "11        O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "12                        O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "\n",
       "[4558 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd485874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b80204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
